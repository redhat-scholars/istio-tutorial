= Monitoring and Tracing
include::_attributes.adoc[]

[#monitoring]
== Monitoring

Out of the box, you get monitoring via Prometheus and Grafana. 

[source,bash]
----
open "$(minishift openshift service grafana -u)/d/1/istio-dashboard?refresh=5s&orgId=1"
----

image:grafana1.png[alt text]

[source,bash]
----
open "$(minishift openshift service grafana -u)/d/UbsSZTDik/istio-workload-dashboard?refresh=5s&orgId=1"
----

to check the "Workload of the services"

image:grafana2.png[alt text]

[#custommetrics]
== Custom Metrics

Istio also allows you to specify custom metrics which can be seen inside of the Prometheus dashboard

[source,bash]
----
open "$(minishift openshift service prometheus -u)/graph?g0.range_input=5m&g0.expr=&g0.tab=0"
----

Add the custom metric and rule. First make sure you are in the "istio-tutorial" directory and then

[source,bash,subs="+macros,+attributes"]
----
istioctl create -f link:{github-repo}/{istiofiles-dir}/recommendation_requestcount.yml[istiofiles/recommendation_requestcount.yml] -n istio-system
----

In the Prometheus dashboard, add the following

[source,bash]
----
istio_requests_total{destination_service="recommendation.tutorial.svc.cluster.local"}
----

and select `Execute`

image:prometheus_custom_metric.png[alt text]

Then run several requests through the system

[source,bash]
----
while true; do curl customer-tutorial.$(minishift ip).nip.io; sleep .5;  done
----

NOTE: You may have to refresh the browser for the Prometheus graph to update. And you may wish to make the interval 5m (5 minutes) as seen in the screenshot above.

[#tracing]
== Tracing

Distributed Tracing involves propagating the tracing context from service to service, usually done by sending certain incoming HTTP headers downstream to outbound requests. For services embedding a http://opentracing.io/[OpenTracing] framework instrumentations such as https://github.com/opentracing-contrib/java-spring-cloud[opentracing-spring-cloud], this might be transparent. For services that are not embedding OpenTracing libraries, this context propagation needs to be done manually.

As OpenTracing is "just" an instrumentation library, a concrete tracer is required in order to actually capture the tracing data and report it to a remote server. Our `customer` and `preference` services ship with http://jaegertracing.io/[Jaeger] as the concrete tracer. the Istio platform automatically sends collected tracing data to Jaeger, so that we are able to see a trace involving all three services, even if our `recommendation` service is not aware of OpenTracing or Jaeger at all.

Our `customer` and `preference` services are using the https://github.com/jaegertracing/jaeger-client-java/tree/master/jaeger-tracerresolver[`TracerResolver`] facility from OpenTracing, so that the concrete tracer can be loaded automatically without our code having a hard dependency on Jaeger. Given that the Jaeger tracer can be configured via environment variables, we don't need to do anything in order to get a properly configured Jaeger tracer ready and registered with OpenTracing. That said, there are cases where it's appropriate to manually configure a tracer. Refer to the Jaeger documentation for more information on how to do that.

Let's open the Jaeger console, select `customer` from the list of services and click `Find Traces`

[source,bash]
----
minishift openshift service tracing --in-browser
----

image:jaegerUI.png[Trace as seen in Jaeger]
